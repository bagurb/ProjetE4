{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet E4\n",
    "\n",
    "## Introduction\n",
    "\n",
    "ModÃ¨le IA pour la reconnaissance d'anomalie chez le patient.\n",
    "* Input : fichier .wav d'un cardiogramme\n",
    "* Process : wav -> spectrogram/png -> neural convolution network\n",
    "* Output : le type d'anomalie \n",
    "\n",
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\basti\\Anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\basti\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.GK7GX5KEQ4F6UYO3P26ULGBQYHGQO7J4.gfortran-win_amd64.dll\n",
      "C:\\Users\\basti\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "mismatch between the number of fields and the number of arrays",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-877680e38d9b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwave\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfft\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpolynomial\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 156\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    157\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mctypeslib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\random\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[1;31m# add these for module-freeze analysis (like PyInstaller)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_pickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_common\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_bounded_integers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\random\\_pickle.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmtrand\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRandomState\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_philox\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPhilox\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_pcg64\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPCG64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPCG64DXSM\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_sfc64\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSFC64\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mmtrand.pyx\u001b[0m in \u001b[0;36minit numpy.random.mtrand\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.__init__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m_mt19937.pyx\u001b[0m in \u001b[0;36mnumpy.random._mt19937.MT19937.__init__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mbit_generator.pyx\u001b[0m in \u001b[0;36mnumpy.random.bit_generator.BitGenerator.__init__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mbit_generator.pyx\u001b[0m in \u001b[0;36mnumpy.random.bit_generator.SeedSequence.__init__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mbit_generator.pyx\u001b[0m in \u001b[0;36mnumpy.random.bit_generator.SeedSequence.get_assembled_entropy\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mbit_generator.pyx\u001b[0m in \u001b[0;36mnumpy.random.bit_generator._coerce_to_uint32_array\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mbit_generator.pyx\u001b[0m in \u001b[0;36mnumpy.random.bit_generator._int_to_uint32_array\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\records.py\u001b[0m in \u001b[0;36marray\u001b[1;34m(obj, dtype, shape, offset, strides, formats, names, titles, aligned, byteorder, copy)\u001b[0m\n\u001b[0;32m   1060\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mfromrecords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1061\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1062\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfromarrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1063\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1064\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\records.py\u001b[0m in \u001b[0;36mfromarrays\u001b[1;34m(arrayList, dtype, shape, formats, names, titles, aligned, byteorder)\u001b[0m\n\u001b[0;32m    658\u001b[0m     \u001b[1;31m# Determine shape from data-type.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    659\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdescr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrayList\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 660\u001b[1;33m         raise ValueError(\"mismatch between the number of fields \"\n\u001b[0m\u001b[0;32m    661\u001b[0m                 \"and the number of arrays\")\n\u001b[0;32m    662\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: mismatch between the number of fields and the number of arrays"
     ]
    }
   ],
   "source": [
    "import wave\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "import splitfolders\n",
    "from keras import layers\n",
    "from keras.layers import Activation, Dense, Dropout, Conv2D, Flatten, MaxPooling2D, GlobalMaxPooling2D, GlobalAveragePooling1D, AveragePooling2D, Input, add\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import pandas as pd\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traitement des donnÃ©es .wav\n",
    "\n",
    "Les fonctions ci-dessous ont pour rÃ´le dans un premier temps de convertir les fichiers .wav contenu dans Data/MLDataset en spectrogramme au format .png dans un dossier Data/Spectrograms/(Known_datas/Unknown_datas)/(CatÃ©gories).\n",
    "\n",
    "* Known_datas : le dossier oÃ¹ sont contenu les datas dont on connait le label (serviront de training et testing set).\n",
    "* Unknown_datas : le dossier contenant des datas dont on ne connait pas le label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RÃ©cupÃ¨re un fichier dont le chemin d'accÃ¨s est path.\n",
    "# On utilise scipy.io.wavfile.read pour rÃ©cupÃ©rer la frÃ©quence (sample_rate) et les datas (sample) du fichier .wav. \n",
    "# On s'assure de crÃ©er le dossier oÃ¹ l'on veut stocker les png.\n",
    "# On monte le spectrogramme Ã  partir de sample_rate et samples puis on sauvegarde sans les axes au format png. \n",
    "def wave_to_spect(path):\n",
    "    path_tokens = path.split(\"/\")\n",
    "    sample_rate, samples = wavfile.read(path)\n",
    "    os.makedirs(\"Data/Spectrograms/\"+path_tokens[2]+\"/\"+path_tokens[3],exist_ok = True)\n",
    "    plt.subplot(212)\n",
    "    plt.specgram(samples, Fs=sample_rate,NFFT=2048,Fc = 0, sides='default',mode='default', scale='dB')\n",
    "    plt.axis('off')\n",
    "    plt.savefig(\"Data/Spectrograms/\"+path_tokens[2]+\"/\"+path_tokens[3]+\"/\"+path_tokens[4].replace(\".wav\",\".png\"))\n",
    "    plt.clf()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Utilisation de la fonction dÃ©crite plus haut sur l'ensemble des donnÃ©es. \n",
    "data_path = \"Data/MLDataset\"\n",
    "for t in os.listdir(data_path):\n",
    "    complete_data_path = os.path.join(data_path,t)\n",
    "    for a in os.listdir(complete_data_path ):\n",
    "        new_data_path = os.path.join(complete_data_path,a)\n",
    "        for filename in os.listdir(new_data_path):\n",
    "            wave_to_spect(os.path.join(new_data_path,filename).replace(\"\\\\\",\"/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 517 files [00:01, 375.56 files/s]\n"
     ]
    }
   ],
   "source": [
    "#Split des donnÃ©es aux labels connus pour crÃ©er un train_set et un validation_set\n",
    "splitfolders.ratio('./Data/Spectrograms/Known_datas',output=\"./Data/Spectrograms/Training\",seed=1337,ratio=(.8,.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ModÃ¨le CovNet\n",
    "\n",
    "CrÃ©ation des train_set,test_set et du modÃ¨le."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ImageDataGenerator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-bc90586d180e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#CrÃ©ation du train_set et du test_set. Rescale des valeurs de couleurs de 0 Ã  255 vers une normalisation de 0 Ã  1.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m train_datagen = ImageDataGenerator(\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mrescale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ImageDataGenerator' is not defined"
     ]
    }
   ],
   "source": [
    "#CrÃ©ation du train_set et du test_set. Rescale des valeurs de couleurs de 0 Ã  255 vers une normalisation de 0 Ã  1.\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "    './Data/Spectrograms/Training/train',\n",
    "    target_size = (288, 432),\n",
    "    batch_size= 19,\n",
    "    class_mode = 'categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "    './Data/Spectrograms/Training/val',\n",
    "    target_size = (288, 432),\n",
    "    batch_size= 19,\n",
    "    class_mode = 'categorical',\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_67 (Conv2D)          (None, 286, 430, 4)       112       \n",
      "                                                                 \n",
      " average_pooling2d_67 (Avera  (None, 143, 215, 4)      0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " activation_79 (Activation)  (None, 143, 215, 4)       0         \n",
      "                                                                 \n",
      " conv2d_68 (Conv2D)          (None, 143, 215, 8)       296       \n",
      "                                                                 \n",
      " average_pooling2d_68 (Avera  (None, 71, 107, 8)       0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " activation_80 (Activation)  (None, 71, 107, 8)        0         \n",
      "                                                                 \n",
      " conv2d_69 (Conv2D)          (None, 71, 107, 8)        584       \n",
      "                                                                 \n",
      " average_pooling2d_69 (Avera  (None, 35, 53, 8)        0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " activation_81 (Activation)  (None, 35, 53, 8)         0         \n",
      "                                                                 \n",
      " conv2d_70 (Conv2D)          (None, 35, 53, 8)         584       \n",
      "                                                                 \n",
      " average_pooling2d_70 (Avera  (None, 17, 26, 8)        0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " activation_82 (Activation)  (None, 17, 26, 8)         0         \n",
      "                                                                 \n",
      " conv2d_71 (Conv2D)          (None, 17, 26, 8)         584       \n",
      "                                                                 \n",
      " average_pooling2d_71 (Avera  (None, 8, 13, 8)         0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " activation_83 (Activation)  (None, 8, 13, 8)          0         \n",
      "                                                                 \n",
      " conv2d_72 (Conv2D)          (None, 8, 13, 8)          584       \n",
      "                                                                 \n",
      " average_pooling2d_72 (Avera  (None, 4, 6, 8)          0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " activation_84 (Activation)  (None, 4, 6, 8)           0         \n",
      "                                                                 \n",
      " conv2d_73 (Conv2D)          (None, 4, 6, 8)           584       \n",
      "                                                                 \n",
      " average_pooling2d_73 (Avera  (None, 2, 3, 8)          0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " activation_85 (Activation)  (None, 2, 3, 8)           0         \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 2, 3, 8)           0         \n",
      "                                                                 \n",
      " activation_86 (Activation)  (None, 2, 3, 8)           0         \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 2, 3, 8)           0         \n",
      "                                                                 \n",
      " activation_87 (Activation)  (None, 2, 3, 8)           0         \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 48)                0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 64)                3136      \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 5)                 325       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,789\n",
      "Trainable params: 6,789\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# CrÃ©ation du modÃ¨le et ajout des layers.\n",
    "# Les modifications des weights et sur les layers n'ont pas encore Ã©tÃ© effÃ©ctuÃ©.\n",
    "\n",
    "model = Sequential()\n",
    "input_shape = (288, 432, 3)#first hidden layer\n",
    "model.add(Conv2D(4, (3,3), input_shape=input_shape))\n",
    "model.add(AveragePooling2D((2,2)))\n",
    "model.add(Activation('relu'))#2nd hidden layer\n",
    "model.add(Conv2D(8, (3, 3), padding=\"same\"))\n",
    "model.add(AveragePooling2D((2, 2)))\n",
    "model.add(Activation('relu'))#3rd hidden layer\n",
    "model.add(Conv2D(8, (3, 3), padding=\"same\"))\n",
    "model.add(AveragePooling2D((2, 2)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(8, (3, 3), padding=\"same\"))\n",
    "model.add(AveragePooling2D((2, 2)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(8, (3, 3), padding=\"same\"))\n",
    "model.add(AveragePooling2D((2, 2)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(8, (3, 3), padding=\"same\"))\n",
    "model.add(AveragePooling2D((2, 2)))\n",
    "model.add(Activation('relu'))#Flatten\n",
    "model.add(Conv2D(8, (3, 3), padding=\"same\"))\n",
    "model.add(AveragePooling2D((2, 2)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(rate=0.8))#Add fully connected layer.\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(rate=0.5))#Output layer\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Dense(5,activation=\"softmax\")) \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "batch_size = 8\n",
    "learning_rate = 0.01\n",
    "decay_rate = learning_rate / epochs\n",
    "momentum = 0.9\n",
    "sgd = SGD(learning_rate=learning_rate, momentum=momentum, decay=decay_rate, nesterov=False)\n",
    "model.compile(optimizer=\"sgd\", loss=\"categorical_crossentropy\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\basti\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4/4 [==============================] - ETA: 2s - loss: 1.4733 - accuracy: 0.52 - ETA: 0s - loss: 1.5284 - accuracy: 0.44 - ETA: 0s - loss: 1.5957 - accuracy: 0.33 - ETA: 0s - loss: 1.5761 - accuracy: 0.3026WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 200 batches). You may need to use the repeat() function when building your dataset.\n",
      "4/4 [==============================] - 3s 707ms/step - loss: 1.5761 - accuracy: 0.3026 - val_loss: 1.5594 - val_accuracy: 0.6095\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - ETA: 1s - loss: 1.4460 - accuracy: 0.21 - ETA: 0s - loss: 1.4409 - accuracy: 0.28 - ETA: 0s - loss: 1.4360 - accuracy: 0.29 - ETA: 0s - loss: 1.5611 - accuracy: 0.23 - 1s 350ms/step - loss: 1.5611 - accuracy: 0.2368\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - ETA: 1s - loss: 1.3693 - accuracy: 0.68 - ETA: 0s - loss: 1.3373 - accuracy: 0.65 - ETA: 0s - loss: 1.3634 - accuracy: 0.59 - ETA: 0s - loss: 1.4700 - accuracy: 0.47 - 1s 336ms/step - loss: 1.4700 - accuracy: 0.4737\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - ETA: 1s - loss: 1.4137 - accuracy: 0.57 - ETA: 0s - loss: 1.5941 - accuracy: 0.36 - ETA: 0s - loss: 1.5143 - accuracy: 0.42 - ETA: 0s - loss: 1.4717 - accuracy: 0.46 - 1s 355ms/step - loss: 1.4717 - accuracy: 0.4605\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - ETA: 1s - loss: 1.1829 - accuracy: 0.57 - ETA: 0s - loss: 1.1253 - accuracy: 0.63 - ETA: 0s - loss: 1.3981 - accuracy: 0.42 - ETA: 0s - loss: 1.3313 - accuracy: 0.46 - 1s 346ms/step - loss: 1.3313 - accuracy: 0.4605\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - ETA: 1s - loss: 2.2074 - accuracy: 0.0000e+ - ETA: 0s - loss: 1.9013 - accuracy: 0.0000e+ - ETA: 0s - loss: 1.8248 - accuracy: 0.0175   - ETA: 0s - loss: 1.7396 - accuracy: 0.15 - 1s 303ms/step - loss: 1.7396 - accuracy: 0.1571\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - ETA: 1s - loss: 1.2241 - accuracy: 0.89 - ETA: 0s - loss: 1.2944 - accuracy: 0.73 - ETA: 0s - loss: 1.2556 - accuracy: 0.75 - ETA: 0s - loss: 1.3950 - accuracy: 0.57 - 1s 336ms/step - loss: 1.3950 - accuracy: 0.5789\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - ETA: 1s - loss: 1.1526 - accuracy: 0.78 - ETA: 0s - loss: 1.1397 - accuracy: 0.84 - ETA: 0s - loss: 1.6349 - accuracy: 0.54 - ETA: 0s - loss: 1.5245 - accuracy: 0.65 - 1s 308ms/step - loss: 1.5245 - accuracy: 0.6571\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - ETA: 1s - loss: 1.7112 - accuracy: 0.15 - ETA: 0s - loss: 1.7620 - accuracy: 0.10 - ETA: 0s - loss: 1.6036 - accuracy: 0.36 - ETA: 0s - loss: 1.6240 - accuracy: 0.28 - 1s 348ms/step - loss: 1.6240 - accuracy: 0.2895\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - ETA: 1s - loss: 1.6533 - accuracy: 0.0000e+ - ETA: 0s - loss: 1.4621 - accuracy: 0.4737   - ETA: 0s - loss: 1.3666 - accuracy: 0.61 - ETA: 0s - loss: 1.5265 - accuracy: 0.46 - 1s 342ms/step - loss: 1.5265 - accuracy: 0.4605\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - ETA: 1s - loss: 1.5659 - accuracy: 0.10 - ETA: 0s - loss: 1.3760 - accuracy: 0.52 - ETA: 0s - loss: 1.3349 - accuracy: 0.64 - ETA: 0s - loss: 1.2580 - accuracy: 0.72 - 1s 336ms/step - loss: 1.2580 - accuracy: 0.7237\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - ETA: 1s - loss: 2.1995 - accuracy: 0.05 - ETA: 0s - loss: 2.0460 - accuracy: 0.02 - ETA: 0s - loss: 1.7782 - accuracy: 0.31 - ETA: 0s - loss: 1.6380 - accuracy: 0.47 - 1s 340ms/step - loss: 1.6380 - accuracy: 0.4737\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - ETA: 1s - loss: 1.1142 - accuracy: 0.94 - ETA: 0s - loss: 1.1494 - accuracy: 0.89 - ETA: 0s - loss: 1.2124 - accuracy: 0.80 - ETA: 0s - loss: 1.4336 - accuracy: 0.60 - 1s 346ms/step - loss: 1.4336 - accuracy: 0.6053\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - ETA: 1s - loss: 1.0972 - accuracy: 1.00 - ETA: 0s - loss: 1.3900 - accuracy: 0.52 - ETA: 0s - loss: 1.5566 - accuracy: 0.35 - ETA: 0s - loss: 1.4587 - accuracy: 0.51 - 1s 357ms/step - loss: 1.4587 - accuracy: 0.5132\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - ETA: 1s - loss: 1.1277 - accuracy: 1.00 - ETA: 0s - loss: 1.0766 - accuracy: 0.97 - ETA: 0s - loss: 1.3238 - accuracy: 0.64 - ETA: 0s - loss: 1.4472 - accuracy: 0.51 - 2s 354ms/step - loss: 1.4472 - accuracy: 0.5132\n",
      "Epoch 16/50\n",
      "4/4 [==============================] - ETA: 1s - loss: 1.2203 - accuracy: 0.94 - ETA: 0s - loss: 1.1453 - accuracy: 0.89 - ETA: 0s - loss: 1.4016 - accuracy: 0.59 - ETA: 0s - loss: 1.3384 - accuracy: 0.68 - 2s 370ms/step - loss: 1.3384 - accuracy: 0.6842\n",
      "Epoch 17/50\n",
      "4/4 [==============================] - ETA: 1s - loss: 1.2824 - accuracy: 0.68 - ETA: 0s - loss: 1.4697 - accuracy: 0.34 - ETA: 0s - loss: 1.2907 - accuracy: 0.56 - ETA: 0s - loss: 1.2346 - accuracy: 0.61 - 2s 359ms/step - loss: 1.2346 - accuracy: 0.6184\n",
      "Epoch 18/50\n",
      "4/4 [==============================] - ETA: 1s - loss: 1.9006 - accuracy: 0.0000e+ - ETA: 0s - loss: 1.4347 - accuracy: 0.4737   - ETA: 0s - loss: 1.2889 - accuracy: 0.60 - ETA: 0s - loss: 1.2133 - accuracy: 0.67 - 1s 327ms/step - loss: 1.2133 - accuracy: 0.6714\n",
      "Epoch 19/50\n",
      "4/4 [==============================] - ETA: 1s - loss: 1.0038 - accuracy: 0.84 - ETA: 0s - loss: 1.7214 - accuracy: 0.42 - ETA: 0s - loss: 1.5178 - accuracy: 0.59 - ETA: 0s - loss: 1.6296 - accuracy: 0.44 - 2s 362ms/step - loss: 1.6296 - accuracy: 0.4474\n",
      "Epoch 20/50\n",
      "4/4 [==============================] - ETA: 1s - loss: 1.6621 - accuracy: 0.0000e+ - ETA: 0s - loss: 1.7625 - accuracy: 0.0000e+ - ETA: 0s - loss: 1.5391 - accuracy: 0.3333   - ETA: 0s - loss: 1.3916 - accuracy: 0.50 - 1s 350ms/step - loss: 1.3916 - accuracy: 0.5000\n",
      "Epoch 21/50\n",
      "4/4 [==============================] - ETA: 1s - loss: 1.0087 - accuracy: 0.94 - ETA: 0s - loss: 0.9592 - accuracy: 0.94 - ETA: 0s - loss: 1.2712 - accuracy: 0.64 - ETA: 0s - loss: 1.1980 - accuracy: 0.73 - 1s 359ms/step - loss: 1.1980 - accuracy: 0.7368\n",
      "Epoch 22/50\n",
      "4/4 [==============================] - ETA: 1s - loss: 2.3323 - accuracy: 0.0000e+ - ETA: 0s - loss: 1.6469 - accuracy: 0.4737   - ETA: 0s - loss: 1.4702 - accuracy: 0.60 - ETA: 0s - loss: 1.5528 - accuracy: 0.45 - 1s 316ms/step - loss: 1.5528 - accuracy: 0.4571\n",
      "Epoch 23/50\n",
      "4/4 [==============================] - ETA: 1s - loss: 1.2305 - accuracy: 0.73 - ETA: 0s - loss: 1.4310 - accuracy: 0.39 - ETA: 0s - loss: 1.6387 - accuracy: 0.26 - ETA: 0s - loss: 1.4960 - accuracy: 0.42 - 1s 358ms/step - loss: 1.4960 - accuracy: 0.4211\n",
      "Epoch 24/50\n",
      "4/4 [==============================] - ETA: 1s - loss: 1.0098 - accuracy: 1.00 - ETA: 0s - loss: 1.0008 - accuracy: 1.00 - ETA: 0s - loss: 1.2443 - accuracy: 0.66 - ETA: 0s - loss: 1.1640 - accuracy: 0.75 - 1s 350ms/step - loss: 1.1640 - accuracy: 0.7500\n",
      "Epoch 25/50\n",
      "4/4 [==============================] - ETA: 1s - loss: 0.7933 - accuracy: 1.00 - ETA: 0s - loss: 0.7932 - accuracy: 1.00 - ETA: 0s - loss: 0.8300 - accuracy: 1.00 - ETA: 0s - loss: 1.2874 - accuracy: 0.75 - 1s 354ms/step - loss: 1.2874 - accuracy: 0.7500\n",
      "Epoch 26/50\n",
      "4/4 [==============================] - ETA: 1s - loss: 0.8966 - accuracy: 1.00 - ETA: 0s - loss: 1.5851 - accuracy: 0.50 - ETA: 0s - loss: 1.6262 - accuracy: 0.33 - ETA: 0s - loss: 1.4614 - accuracy: 0.50 - 1s 351ms/step - loss: 1.4614 - accuracy: 0.5000\n",
      "Epoch 27/50\n",
      "4/4 [==============================] - ETA: 1s - loss: 1.1562 - accuracy: 0.68 - ETA: 0s - loss: 1.0042 - accuracy: 0.84 - ETA: 0s - loss: 0.9575 - accuracy: 0.89 - ETA: 0s - loss: 0.9274 - accuracy: 0.92 - 2s 362ms/step - loss: 0.9274 - accuracy: 0.9211\n",
      "Epoch 28/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7891 - accuracy: 0.92 - ETA: 0s - loss: 1.6314 - accuracy: 0.37 - ETA: 0s - loss: 1.7391 - accuracy: 0.23 - ETA: 0s - loss: 1.7164 - accuracy: 0.17 - 1s 344ms/step - loss: 1.7164 - accuracy: 0.1714\n",
      "Epoch 29/50\n",
      "4/4 [==============================] - ETA: 1s - loss: 0.9929 - accuracy: 0.94 - ETA: 0s - loss: 0.9166 - accuracy: 0.97 - ETA: 0s - loss: 0.8886 - accuracy: 0.98 - ETA: 0s - loss: 0.8574 - accuracy: 0.98 - 1s 326ms/step - loss: 0.8574 - accuracy: 0.9857\n",
      "Epoch 30/50\n",
      "4/4 [==============================] - ETA: 1s - loss: 0.8167 - accuracy: 0.94 - ETA: 0s - loss: 1.3114 - accuracy: 0.50 - ETA: 0s - loss: 1.4743 - accuracy: 0.33 - ETA: 0s - loss: 1.2956 - accuracy: 0.50 - 1s 353ms/step - loss: 1.2956 - accuracy: 0.5000\n",
      "Epoch 31/50\n",
      "4/4 [==============================] - ETA: 1s - loss: 1.7864 - accuracy: 0.0000e+ - ETA: 0s - loss: 1.3004 - accuracy: 0.5000   - ETA: 0s - loss: 1.4411 - accuracy: 0.33 - ETA: 0s - loss: 1.5693 - accuracy: 0.25 - 2s 361ms/step - loss: 1.5693 - accuracy: 0.2500\n",
      "Epoch 32/50\n",
      "4/4 [==============================] - ETA: 1s - loss: 0.8643 - accuracy: 0.94 - ETA: 0s - loss: 0.8908 - accuracy: 0.97 - ETA: 0s - loss: 0.9162 - accuracy: 0.89 - ETA: 0s - loss: 1.3779 - accuracy: 0.67 - 1s 367ms/step - loss: 1.3779 - accuracy: 0.6711\n",
      "Epoch 33/50\n",
      "4/4 [==============================] - ETA: 1s - loss: 0.8931 - accuracy: 0.94 - ETA: 0s - loss: 0.9088 - accuracy: 0.94 - ETA: 0s - loss: 0.8803 - accuracy: 0.96 - ETA: 0s - loss: 1.0906 - accuracy: 0.72 - 1s 354ms/step - loss: 1.0906 - accuracy: 0.7237\n",
      "Epoch 34/50\n",
      "4/4 [==============================] - ETA: 1s - loss: 1.6666 - accuracy: 0.0000e+ - ETA: 0s - loss: 1.9163 - accuracy: 0.0000e+ - ETA: 0s - loss: 1.9557 - accuracy: 0.0000e+ - ETA: 0s - loss: 1.8587 - accuracy: 0.0000e+ - 1s 361ms/step - loss: 1.8587 - accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "4/4 [==============================] - ETA: 1s - loss: 0.9754 - accuracy: 0.94 - ETA: 0s - loss: 1.2606 - accuracy: 0.47 - ETA: 0s - loss: 1.1540 - accuracy: 0.64 - ETA: 0s - loss: 1.1104 - accuracy: 0.73 - 1s 354ms/step - loss: 1.1104 - accuracy: 0.7368\n",
      "Epoch 36/50\n",
      "4/4 [==============================] - ETA: 1s - loss: 0.8937 - accuracy: 1.00 - ETA: 0s - loss: 1.4870 - accuracy: 0.50 - ETA: 0s - loss: 1.2711 - accuracy: 0.66 - ETA: 0s - loss: 1.5213 - accuracy: 0.50 - 1s 345ms/step - loss: 1.5213 - accuracy: 0.5000\n",
      "Epoch 37/50\n",
      "4/4 [==============================] - ETA: 1s - loss: 1.0083 - accuracy: 1.00 - ETA: 0s - loss: 1.3313 - accuracy: 0.50 - ETA: 0s - loss: 1.1909 - accuracy: 0.66 - ETA: 0s - loss: 1.0996 - accuracy: 0.75 - 1s 358ms/step - loss: 1.0996 - accuracy: 0.7500\n",
      "Epoch 38/50\n",
      "4/4 [==============================] - ETA: 1s - loss: 0.9063 - accuracy: 1.00 - ETA: 0s - loss: 0.8322 - accuracy: 0.97 - ETA: 0s - loss: 1.3517 - accuracy: 0.64 - ETA: 0s - loss: 1.2650 - accuracy: 0.71 - 1s 321ms/step - loss: 1.2650 - accuracy: 0.7143\n",
      "Epoch 39/50\n",
      "4/4 [==============================] - ETA: 1s - loss: 0.8344 - accuracy: 1.00 - ETA: 0s - loss: 0.7690 - accuracy: 1.00 - ETA: 0s - loss: 0.7581 - accuracy: 1.00 - ETA: 0s - loss: 0.7313 - accuracy: 1.00 - 1s 320ms/step - loss: 0.7313 - accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "4/4 [==============================] - ETA: 1s - loss: 0.6761 - accuracy: 1.00 - ETA: 0s - loss: 0.6277 - accuracy: 0.97 - ETA: 0s - loss: 0.6001 - accuracy: 0.98 - ETA: 0s - loss: 1.2946 - accuracy: 0.73 - 1s 346ms/step - loss: 1.2946 - accuracy: 0.7368\n",
      "Epoch 41/50\n",
      "4/4 [==============================] - ETA: 1s - loss: 1.6156 - accuracy: 0.0000e+ - ETA: 0s - loss: 1.1576 - accuracy: 0.5000   - ETA: 0s - loss: 1.0064 - accuracy: 0.66 - ETA: 0s - loss: 0.9101 - accuracy: 0.75 - 1s 344ms/step - loss: 0.9101 - accuracy: 0.7500\n",
      "Epoch 42/50\n",
      "4/4 [==============================] - ETA: 1s - loss: 0.6692 - accuracy: 1.00 - ETA: 0s - loss: 1.3083 - accuracy: 0.50 - ETA: 0s - loss: 1.0917 - accuracy: 0.66 - ETA: 0s - loss: 0.9636 - accuracy: 0.75 - 1s 352ms/step - loss: 0.9636 - accuracy: 0.7500\n",
      "Epoch 43/50\n",
      "4/4 [==============================] - ETA: 1s - loss: 0.5707 - accuracy: 1.00 - ETA: 0s - loss: 0.5714 - accuracy: 1.00 - ETA: 0s - loss: 0.5970 - accuracy: 0.98 - ETA: 0s - loss: 1.0235 - accuracy: 0.73 - 2s 428ms/step - loss: 1.0235 - accuracy: 0.7368\n",
      "Epoch 44/50\n",
      "4/4 [==============================] - ETA: 1s - loss: 1.9560 - accuracy: 0.0000e+ - ETA: 0s - loss: 2.2516 - accuracy: 0.0000e+ - ETA: 0s - loss: 2.2539 - accuracy: 0.0000e+ - ETA: 0s - loss: 2.2355 - accuracy: 0.0000e+ - 2s 420ms/step - loss: 2.2355 - accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "4/4 [==============================] - ETA: 1s - loss: 2.1683 - accuracy: 0.0000e+ - ETA: 0s - loss: 1.5210 - accuracy: 0.5000   - ETA: 0s - loss: 1.3002 - accuracy: 0.66 - ETA: 0s - loss: 1.1657 - accuracy: 0.75 - 2s 362ms/step - loss: 1.1657 - accuracy: 0.7500\n",
      "Epoch 46/50\n",
      "4/4 [==============================] - ETA: 1s - loss: 2.0448 - accuracy: 0.0000e+ - ETA: 0s - loss: 1.4273 - accuracy: 0.5000   - ETA: 0s - loss: 1.2123 - accuracy: 0.66 - ETA: 0s - loss: 1.1023 - accuracy: 0.75 - 2s 363ms/step - loss: 1.1023 - accuracy: 0.7500\n",
      "Epoch 47/50\n",
      "4/4 [==============================] - ETA: 1s - loss: 0.6566 - accuracy: 1.00 - ETA: 0s - loss: 0.6753 - accuracy: 1.00 - ETA: 0s - loss: 0.6726 - accuracy: 1.00 - ETA: 0s - loss: 1.0421 - accuracy: 0.72 - 1s 353ms/step - loss: 1.0421 - accuracy: 0.7286\n",
      "Epoch 48/50\n",
      "4/4 [==============================] - ETA: 1s - loss: 2.3611 - accuracy: 0.0000e+ - ETA: 0s - loss: 1.5747 - accuracy: 0.5000   - ETA: 0s - loss: 1.2500 - accuracy: 0.66 - ETA: 0s - loss: 1.1068 - accuracy: 0.75 - 2s 354ms/step - loss: 1.1068 - accuracy: 0.7500\n",
      "Epoch 49/50\n",
      "4/4 [==============================] - ETA: 1s - loss: 2.4098 - accuracy: 0.0000e+ - ETA: 0s - loss: 1.5517 - accuracy: 0.5000   - ETA: 0s - loss: 1.2756 - accuracy: 0.66 - ETA: 0s - loss: 1.0997 - accuracy: 0.75 - 2s 410ms/step - loss: 1.0997 - accuracy: 0.7500\n",
      "Epoch 50/50\n",
      "4/4 [==============================] - ETA: 1s - loss: 2.5166 - accuracy: 0.0000e+ - ETA: 0s - loss: 2.2984 - accuracy: 0.0000e+ - ETA: 0s - loss: 2.2213 - accuracy: 0.0000e+ - ETA: 0s - loss: 1.8739 - accuracy: 0.2500   - 2s 385ms/step - loss: 1.8739 - accuracy: 0.2500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fe00165b48>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrainement du modÃ¨le\n",
    "model.fit_generator(\n",
    "        training_set,\n",
    "        steps_per_epoch=4,\n",
    "        epochs=50,\n",
    "        validation_data=test_set,\n",
    "        validation_steps=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\basti\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3874943256378174, 0.46052631735801697]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluation du modÃ¨le\n",
    "model.evaluate_generator(generator = test_set, steps=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\basti\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 6/13 [============>.................] - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA: 1sWARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 13 batches). You may need to use the repeat() function when building your dataset.\n",
      "13/13 [==============================] - 1s 77ms/step\n"
     ]
    }
   ],
   "source": [
    "#Prediction sur les donnÃ©es test\n",
    "test_set.reset()\n",
    "pred = model.predict_generator(test_set, steps=13, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n"
     ]
    }
   ],
   "source": [
    "# LabÃ©lisation des rÃ©sultats\n",
    "predicted_class_indices = np.argmax(pred,axis=1)\n",
    "encoded = to_categorical(predicted_class_indices)\n",
    "predicted_values = [np.argmax(encoded[i]) for i in range(len(encoded))]\n",
    "labels = (training_set.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predictions = [labels[k] for k in predicted_values]\n",
    "predictions = predictions[:200]\n",
    "filenames = test_set.filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105 105\n"
     ]
    }
   ],
   "source": [
    "#On vÃ©rifie que le nombre de prediction = le nombre de files\n",
    "print(len(filenames),len(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CrÃ©ation d'un csv pour visualiser les rÃ©sultats.\n",
    "results = pd.DataFrame({\"Filename\":filenames,\n",
    "\"Predictions\":predictions})\n",
    "results.to_csv('prediction_results.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "07efdcd4b820c98a756949507a4d29d7862823915ec7477944641bea022f4f62"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
