{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet E4\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Mod√®le IA pour la reconnaissance d'anomalie chez le patient.\n",
    "* Input : fichier .wav d'un cardiogramme\n",
    "* Process : reconnaissance de l'anomalie\n",
    "* Output : le type d'anomalie \n",
    "\n",
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wave\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "import splitfolders\n",
    "from keras import layers\n",
    "from keras.layers import Activation, Dense, Dropout, Conv2D, Flatten, MaxPooling2D, GlobalMaxPooling2D, GlobalAveragePooling1D, AveragePooling2D, Input, add\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import pandas as pd\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Data', 'MLDataset', 'Training', 'Normal', '101_1305030823364_B.wav']\n"
     ]
    }
   ],
   "source": [
    "path = \"Data/MLDataset/Training/Normal/101_1305030823364_B.wav\"\n",
    "path_tokens = path.split(\"/\")\n",
    "print(path_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wave_to_spect(path):\n",
    "    path_tokens = path.split(\"/\")\n",
    "    sample_rate, samples = wavfile.read(path)\n",
    "    os.makedirs(\"Data/Spectrograms/\"+path_tokens[2]+\"/\"+path_tokens[3],exist_ok = True)\n",
    "    plt.subplot(212)\n",
    "    plt.specgram(samples, Fs=sample_rate,NFFT=2048,Fc = 0, sides='default',mode='default', scale='dB')\n",
    "    plt.axis('off')\n",
    "    plt.savefig(\"Data/Spectrograms/\"+path_tokens[2]+\"/\"+path_tokens[3]+\"/\"+path_tokens[4].replace(\".wav\",\".png\"))\n",
    "    plt.clf()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "data_path = \"Data/MLDataset\"\n",
    "for t in os.listdir(data_path):\n",
    "    complete_data_path = os.path.join(data_path,t)\n",
    "    for a in os.listdir(complete_data_path ):\n",
    "        new_data_path = os.path.join(complete_data_path,a)\n",
    "        for filename in os.listdir(new_data_path):\n",
    "            wave_to_spect(os.path.join(new_data_path,filename).replace(\"\\\\\",\"/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 517 files [00:01, 375.56 files/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "splitfolders.ratio('./Data/Spectrograms/Known_datas',output=\"./Data/Spectrograms/Training\",seed=1337,ratio=(.8,.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 412 images belonging to 5 classes.\n",
      "Found 105 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "    './Data/Spectrograms/Training/train',\n",
    "    target_size = (288, 432),\n",
    "    batch_size= 19,\n",
    "    class_mode = 'categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "    './Data/Spectrograms/Training/val',\n",
    "    target_size = (288, 432),\n",
    "    batch_size= 19,\n",
    "    class_mode = 'categorical',\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 143, 215, 32)      896       \n",
      "                                                                 \n",
      " average_pooling2d_3 (Averag  (None, 71, 107, 32)      0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 71, 107, 32)       0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 71, 107, 64)       18496     \n",
      "                                                                 \n",
      " average_pooling2d_4 (Averag  (None, 35, 53, 64)       0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 35, 53, 64)        0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 35, 53, 64)        36928     \n",
      "                                                                 \n",
      " average_pooling2d_5 (Averag  (None, 17, 26, 64)       0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 17, 26, 64)        0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 28288)             0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 28288)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                1810496   \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 64)                0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 5)                 325       \n",
      "                                                                 \n",
      " activation_9 (Activation)   (None, 5)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,867,141\n",
      "Trainable params: 1,867,141\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "input_shape = (288, 432, 3)#first hidden layer\n",
    "model.add(Conv2D(32, (3,3), strides= (2,2), input_shape=input_shape))\n",
    "model.add(AveragePooling2D((2,2),strides = (2,2)))\n",
    "model.add(Activation('relu'))#2nd hidden layer\n",
    "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "model.add(AveragePooling2D((2, 2), strides=(2,2)))\n",
    "model.add(Activation('relu'))#3rd hidden layer\n",
    "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "model.add(AveragePooling2D((2, 2), strides=(2,2)))\n",
    "model.add(Activation('relu'))#Flatten\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(rate=0.5))#Add fully connected layer.\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(rate=0.5))#Output layer\n",
    "model.add(Dense(5))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "batch_size = 8\n",
    "learning_rate = 0.01\n",
    "decay_rate = learning_rate / epochs\n",
    "momentum = 0.9\n",
    "sgd = SGD(learning_rate=learning_rate, momentum=momentum, decay=decay_rate, nesterov=False)\n",
    "model.compile(optimizer=\"sgd\", loss=\"categorical_crossentropy\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\AppData\\Local\\Temp/ipykernel_31648/2132631962.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.5299 - accuracy: 0.5000WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 200 batches). You may need to use the repeat() function when building your dataset.\n",
      "4/4 [==============================] - 4s 1s/step - loss: 1.5299 - accuracy: 0.5000 - val_loss: 1.4442 - val_accuracy: 0.6095\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 3s 617ms/step - loss: 1.4361 - accuracy: 0.6286\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 3s 692ms/step - loss: 1.4235 - accuracy: 0.6842\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 3s 713ms/step - loss: 1.3687 - accuracy: 0.7500\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 3s 678ms/step - loss: 0.3243 - accuracy: 1.0000\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 3s 706ms/step - loss: 2.0028 - accuracy: 0.1842\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 3s 682ms/step - loss: 1.5267 - accuracy: 0.5000\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 3s 690ms/step - loss: 1.2278 - accuracy: 0.7500\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 3s 717ms/step - loss: 1.6017 - accuracy: 0.5000\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 3s 661ms/step - loss: 1.3032 - accuracy: 0.6316\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 3s 685ms/step - loss: 1.4425 - accuracy: 0.7286\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 3s 703ms/step - loss: 1.5486 - accuracy: 0.5000\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 3s 715ms/step - loss: 1.4421 - accuracy: 0.5000\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - 3s 725ms/step - loss: 1.3970 - accuracy: 0.5000\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - 3s 687ms/step - loss: 1.1892 - accuracy: 0.7500\n",
      "Epoch 16/50\n",
      "4/4 [==============================] - 3s 685ms/step - loss: 1.7434 - accuracy: 0.2500\n",
      "Epoch 17/50\n",
      "4/4 [==============================] - 3s 709ms/step - loss: 0.9142 - accuracy: 0.9342\n",
      "Epoch 18/50\n",
      "4/4 [==============================] - 3s 762ms/step - loss: 1.6649 - accuracy: 0.5000\n",
      "Epoch 19/50\n",
      "4/4 [==============================] - 3s 754ms/step - loss: 1.4737 - accuracy: 0.4342\n",
      "Epoch 20/50\n",
      "4/4 [==============================] - 3s 799ms/step - loss: 1.4331 - accuracy: 0.5000\n",
      "Epoch 21/50\n",
      "4/4 [==============================] - 3s 798ms/step - loss: 1.2631 - accuracy: 0.7500\n",
      "Epoch 22/50\n",
      "4/4 [==============================] - 3s 699ms/step - loss: 1.1281 - accuracy: 0.7286\n",
      "Epoch 23/50\n",
      "4/4 [==============================] - 3s 723ms/step - loss: 1.2967 - accuracy: 0.6842\n",
      "Epoch 24/50\n",
      "4/4 [==============================] - 3s 704ms/step - loss: 1.5469 - accuracy: 0.5000\n",
      "Epoch 25/50\n",
      "4/4 [==============================] - 3s 709ms/step - loss: 1.6802 - accuracy: 0.2500\n",
      "Epoch 26/50\n",
      "4/4 [==============================] - 3s 685ms/step - loss: 1.2037 - accuracy: 0.7500\n",
      "Epoch 27/50\n",
      "4/4 [==============================] - 3s 741ms/step - loss: 1.0419 - accuracy: 0.7500\n",
      "Epoch 28/50\n",
      "4/4 [==============================] - 3s 829ms/step - loss: 1.4850 - accuracy: 0.5000\n",
      "Epoch 29/50\n",
      "4/4 [==============================] - 3s 776ms/step - loss: 1.4701 - accuracy: 0.4342\n",
      "Epoch 30/50\n",
      "4/4 [==============================] - 3s 732ms/step - loss: 1.6809 - accuracy: 0.2500\n",
      "Epoch 31/50\n",
      "4/4 [==============================] - 3s 806ms/step - loss: 0.9128 - accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "4/4 [==============================] - 4s 819ms/step - loss: 1.5864 - accuracy: 0.5000\n",
      "Epoch 33/50\n",
      "4/4 [==============================] - 3s 696ms/step - loss: 1.0594 - accuracy: 0.7500\n",
      "Epoch 34/50\n",
      "4/4 [==============================] - 3s 701ms/step - loss: 0.9702 - accuracy: 0.7632\n",
      "Epoch 35/50\n",
      "4/4 [==============================] - 3s 707ms/step - loss: 1.0634 - accuracy: 0.7500\n",
      "Epoch 36/50\n",
      "4/4 [==============================] - 3s 634ms/step - loss: 0.4557 - accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "4/4 [==============================] - 3s 707ms/step - loss: 1.6498 - accuracy: 0.6842\n",
      "Epoch 38/50\n",
      "4/4 [==============================] - 3s 768ms/step - loss: 1.4752 - accuracy: 0.5000\n",
      "Epoch 39/50\n",
      "4/4 [==============================] - 3s 758ms/step - loss: 0.6224 - accuracy: 0.9342\n",
      "Epoch 40/50\n",
      "4/4 [==============================] - 3s 666ms/step - loss: 2.0510 - accuracy: 0.1842\n",
      "Epoch 41/50\n",
      "4/4 [==============================] - 3s 706ms/step - loss: 1.1752 - accuracy: 0.7286\n",
      "Epoch 42/50\n",
      "4/4 [==============================] - 3s 721ms/step - loss: 1.2944 - accuracy: 0.5000\n",
      "Epoch 43/50\n",
      "4/4 [==============================] - 3s 621ms/step - loss: 1.1201 - accuracy: 0.6571\n",
      "Epoch 44/50\n",
      "4/4 [==============================] - 3s 687ms/step - loss: 1.5938 - accuracy: 0.5000\n",
      "Epoch 45/50\n",
      "4/4 [==============================] - 3s 699ms/step - loss: 0.5649 - accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "4/4 [==============================] - 3s 590ms/step - loss: 1.1064 - accuracy: 0.7286\n",
      "Epoch 47/50\n",
      "4/4 [==============================] - 3s 636ms/step - loss: 1.0463 - accuracy: 0.7286\n",
      "Epoch 48/50\n",
      "4/4 [==============================] - 3s 704ms/step - loss: 0.3692 - accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "4/4 [==============================] - 3s 677ms/step - loss: 1.2423 - accuracy: 0.7500\n",
      "Epoch 50/50\n",
      "4/4 [==============================] - 3s 694ms/step - loss: 0.4485 - accuracy: 0.9342\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21ed399e850>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "        training_set,\n",
    "        steps_per_epoch=4,\n",
    "        epochs=50,\n",
    "        validation_data=test_set,\n",
    "        validation_steps=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\AppData\\Local\\Temp/ipykernel_31648/2577163855.py:1: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
      "  model.evaluate_generator(generator = test_set, steps=4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.7070904970169067, 0.46052631735801697]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate_generator(generator = test_set, steps=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\AppData\\Local\\Temp/ipykernel_31648/494329537.py:2: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  pred = model.predict_generator(test_set, steps=13, verbose=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 6/13 [============>.................] - ETA: 0sWARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 13 batches). You may need to use the repeat() function when building your dataset.\n",
      "13/13 [==============================] - 1s 58ms/step\n"
     ]
    }
   ],
   "source": [
    "test_set.reset()\n",
    "pred = model.predict_generator(test_set, steps=13, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Artifact\\\\201106021541.png', 'Artifact\\\\201106101314.png', 'Artifact\\\\201106110909.png', 'Artifact\\\\201106111119.png', 'Artifact\\\\201106190520.png', 'Artifact\\\\201106211430.png', 'Artifact\\\\201106212112.png', 'Artifact\\\\201106221254.png', 'Extrahs\\\\201101161027.png', 'Extrahs\\\\201102241217.png', 'Extrahs\\\\201103150114.png', 'Extrahs\\\\201104270458.png', 'Extrasystole\\\\153_1306848820671_C.png', 'Extrasystole\\\\198_1308141739338_B1.png', 'Extrasystole\\\\202_1308145175747_C2.png', 'Extrasystole\\\\207_1308159792607_B1.png', 'Extrasystole\\\\209_1308162216750_D.png', 'Extrasystole\\\\235_1308749032454_B.png', 'Extrasystole\\\\237_1308750231222_C.png', 'Extrasystole\\\\249_1309202052376_C.png', 'Extrasystole\\\\261_1309353556003_C.png', 'Extrasystole\\\\286_1311170606028_D.png', 'Murmur\\\\135_1306428972976_A.png', 'Murmur\\\\156_1306936373241_B1.png', 'Murmur\\\\162_1307101835989_B.png', 'Murmur\\\\164_1307106095995_C1.png', 'Murmur\\\\193_1308078104592_B.png', 'Murmur\\\\195_1308140095331_A.png', 'Murmur\\\\196_1308141034858_C.png', 'Murmur\\\\197_1308141235553_D.png', 'Murmur\\\\200_1308144251434_C.png', 'Murmur\\\\200_1308144251434_D.png', 'Murmur\\\\203_1308162026258_D.png', 'Murmur\\\\243_1309197760898_B.png', 'Murmur\\\\248_1309201683806_C.png', 'Murmur\\\\254_1309350589009_A.png', 'Murmur\\\\276_1311162716489_C.png', 'Murmur\\\\281_1311165683454_B.png', 'Murmur\\\\281_1311165683454_D.png', 'Murmur\\\\292_1311185449649_D.png', 'Murmur\\\\293_1311680805936_B1.png', 'Normal\\\\104_1305032492469_A.png', 'Normal\\\\105_1305033453095_C.png', 'Normal\\\\106_1306776721273_A.png', 'Normal\\\\106_1306776721273_C2.png', 'Normal\\\\109_1305653972028_C.png', 'Normal\\\\109_1305653972028_E.png', 'Normal\\\\110_1305655332337_A.png', 'Normal\\\\113_1306244002866_A.png', 'Normal\\\\117_1306262456650_A.png', 'Normal\\\\117_1306262456650_B.png', 'Normal\\\\117_1306262456650_D.png', 'Normal\\\\126_1306777102824_D.png', 'Normal\\\\127_1306764300147_B.png', 'Normal\\\\128_1306344005749_D1.png', 'Normal\\\\136_1306429977501_D1.png', 'Normal\\\\137_1306764999211_B.png', 'Normal\\\\138_1306762146980_A.png', 'Normal\\\\139_1306519274653_A.png', 'Normal\\\\141_1306520154450_A1.png', 'Normal\\\\141_1306520154450_B1.png', 'Normal\\\\141_1306520154450_C1.png', 'Normal\\\\143_1306763822290_B.png', 'Normal\\\\146_1306778707532_D.png', 'Normal\\\\148_1306768801551_D2.png', 'Normal\\\\150_1306776340746_B.png', 'Normal\\\\151_1306779785624_C.png', 'Normal\\\\151_1306779785624_D.png', 'Normal\\\\154_1306935608852_B1.png', 'Normal\\\\159_1307018640315_A1.png', 'Normal\\\\159_1307018640315_B1.png', 'Normal\\\\159_1307018640315_B2.png', 'Normal\\\\169_1307970398039_A.png', 'Normal\\\\172_1307971284351_B1.png', 'Normal\\\\173_1307973611151_C.png', 'Normal\\\\175_1307987962616_B.png', 'Normal\\\\175_1307987962616_D.png', 'Normal\\\\176_1307988171173_A.png', 'Normal\\\\178_1307989887769_B1.png', 'Normal\\\\180_1307990956284_A.png', 'Normal\\\\181_1308052613891_D.png', 'Normal\\\\183_1308072703477_B.png', 'Normal\\\\184_1308073010307_B.png', 'Normal\\\\190_1308076920011_D.png', 'Normal\\\\194_1308139824187_C.png', 'Normal\\\\207_1308159792607_C.png', 'Normal\\\\208_1308159994503_C.png', 'Normal\\\\209_1308162216750_A.png', 'Normal\\\\209_1308162216750_A1.png', 'Normal\\\\218_1308246311449_C1.png', 'Normal\\\\227_1308594233667_B.png', 'Normal\\\\232_1308748524018_B.png', 'Normal\\\\250_1309202496494_A.png', 'Normal\\\\258_1309352253234_A.png', 'Normal\\\\262_1309355283807_A.png', 'Normal\\\\264_1309356143724_B.png', 'Normal\\\\264_1309356143724_D.png', 'Normal\\\\274_1311075637574_B.png', 'Normal\\\\274_1311075637574_D.png', 'Normal\\\\278_1311163365896_B.png', 'Normal\\\\284_1311168471850_A.png', 'Normal\\\\294_1311681084248_B.png', 'Normal\\\\296_1311682952647_A1.png', 'Normal\\\\296_1311682952647_C.png', 'Normal\\\\298_1311685888900_B.png']\n"
     ]
    }
   ],
   "source": [
    "predicted_class_indices = np.argmax(pred,axis=1)\n",
    "\n",
    "labels = (training_set.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predictions = [labels[k] for k in predicted_class_indices]\n",
    "predictions = predictions[:200]\n",
    "filenames = test_set.filenames\n",
    "print(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105 105\n"
     ]
    }
   ],
   "source": [
    "print(len(filenames),len(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({\"Filename\":filenames,\n",
    "\"Predictions\":predictions})\n",
    "results.to_csv('prediction_results.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "07efdcd4b820c98a756949507a4d29d7862823915ec7477944641bea022f4f62"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
