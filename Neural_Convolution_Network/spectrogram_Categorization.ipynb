{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet E4\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Modèle IA pour la reconnaissance d'anomalie chez le patient.\n",
    "* Input : fichier .wav d'un cardiogramme\n",
    "* Process : wav -> spectrogram/png -> neural convolution network\n",
    "* Output : le type d'anomalie \n",
    "\n",
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wave\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "import splitfolders\n",
    "from keras import layers\n",
    "from keras.layers import Activation, Dense, Dropout, Conv2D, Flatten, MaxPooling2D, GlobalMaxPooling2D, GlobalAveragePooling1D, AveragePooling2D, Input, add\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import pandas as pd\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traitement des données .wav\n",
    "\n",
    "Les fonctions ci-dessous ont pour rôle dans un premier temps de convertir les fichiers .wav contenu dans Data/MLDataset en spectrogramme au format .png dans un dossier Data/Spectrograms/(Known_datas/Unknown_datas)/(Catégories).\n",
    "\n",
    "* Known_datas : le dossier où sont contenu les datas dont on connait le label (serviront de training et testing set).\n",
    "* Unknown_datas : le dossier contenant des datas dont on ne connait pas le label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupère un fichier dont le chemin d'accès est path.\n",
    "# On utilise scipy.io.wavfile.read pour récupérer la fréquence (sample_rate) et les datas (sample) du fichier .wav. \n",
    "# On s'assure de créer le dossier où l'on veut stocker les png.\n",
    "# On monte le spectrogramme à partir de sample_rate et samples puis on sauvegarde sans les axes au format png. \n",
    "def wave_to_spect(path):\n",
    "    path_tokens = path.split(\"/\")\n",
    "    sample_rate, samples = wavfile.read(path)\n",
    "    os.makedirs(\"Data/Spectrograms/\"+path_tokens[2]+\"/\"+path_tokens[3],exist_ok = True)\n",
    "    plt.subplot(212)\n",
    "    plt.specgram(samples, Fs=sample_rate,NFFT=2048,Fc = 0, sides='default',mode='default', scale='dB')\n",
    "    plt.axis('off')\n",
    "    plt.savefig(\"Data/Spectrograms/\"+path_tokens[2]+\"/\"+path_tokens[3]+\"/\"+path_tokens[4].replace(\".wav\",\".png\"))\n",
    "    plt.clf()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "#Utilisation de la fonction décrite plus haut sur l'ensemble des données. \n",
    "data_path = \"Data/MLDataset\"\n",
    "for t in os.listdir(data_path):\n",
    "    complete_data_path = os.path.join(data_path,t)\n",
    "    for a in os.listdir(complete_data_path ):\n",
    "        new_data_path = os.path.join(complete_data_path,a)\n",
    "        for filename in os.listdir(new_data_path):\n",
    "            wave_to_spect(os.path.join(new_data_path,filename).replace(\"\\\\\",\"/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 517 files [00:01, 375.56 files/s]\n"
     ]
    }
   ],
   "source": [
    "#Split des données aux labels connus pour créer un train_set et un validation_set\n",
    "splitfolders.ratio('./Data/Spectrograms/Known_datas',output=\"./Data/Spectrograms/Training\",seed=1337,ratio=(.8,.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modèle CovNet\n",
    "\n",
    "Création des train_set,test_set et du modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 412 images belonging to 5 classes.\n",
      "Found 105 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "#Création du train_set et du test_set. Rescale des valeurs de couleurs de 0 à 255 vers une normalisation de 0 à 1.\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "    './Data/Spectrograms/Training/train',\n",
    "    target_size = (288, 432),\n",
    "    batch_size= 19,\n",
    "    class_mode = 'categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "    './Data/Spectrograms/Training/val',\n",
    "    target_size = (288, 432),\n",
    "    batch_size= 19,\n",
    "    class_mode = 'categorical',\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_20 (Conv2D)          (None, 286, 430, 32)      896       \n",
      "                                                                 \n",
      " average_pooling2d_20 (Avera  (None, 143, 215, 32)     0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " activation_30 (Activation)  (None, 143, 215, 32)      0         \n",
      "                                                                 \n",
      " conv2d_21 (Conv2D)          (None, 143, 215, 64)      18496     \n",
      "                                                                 \n",
      " average_pooling2d_21 (Avera  (None, 71, 107, 64)      0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " activation_31 (Activation)  (None, 71, 107, 64)       0         \n",
      "                                                                 \n",
      " conv2d_22 (Conv2D)          (None, 71, 107, 64)       36928     \n",
      "                                                                 \n",
      " average_pooling2d_22 (Avera  (None, 35, 53, 64)       0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 35, 53, 64)        36928     \n",
      "                                                                 \n",
      " average_pooling2d_23 (Avera  (None, 17, 26, 64)       0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " conv2d_24 (Conv2D)          (None, 17, 26, 64)        36928     \n",
      "                                                                 \n",
      " average_pooling2d_24 (Avera  (None, 8, 13, 64)        0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " conv2d_25 (Conv2D)          (None, 8, 13, 64)         36928     \n",
      "                                                                 \n",
      " average_pooling2d_25 (Avera  (None, 4, 6, 64)         0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " activation_32 (Activation)  (None, 4, 6, 64)          0         \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 1536)              0         \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 1536)              0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 64)                98368     \n",
      "                                                                 \n",
      " activation_33 (Activation)  (None, 64)                0         \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 5)                 325       \n",
      "                                                                 \n",
      " activation_34 (Activation)  (None, 5)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 265,797\n",
      "Trainable params: 265,797\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Création du modèle et ajout des layers.\n",
    "# Les modifications des weights et sur les layers n'ont pas encore été efféctué.\n",
    "\n",
    "model = Sequential()\n",
    "input_shape = (288, 432, 3)#first hidden layer\n",
    "model.add(Conv2D(32, (3,3), input_shape=input_shape))\n",
    "model.add(AveragePooling2D((2,2)))\n",
    "model.add(Activation('relu'))#2nd hidden layer\n",
    "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "model.add(AveragePooling2D((2, 2)))\n",
    "model.add(Activation('relu'))#3rd hidden layer\n",
    "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "model.add(AveragePooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "model.add(AveragePooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "model.add(AveragePooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "model.add(AveragePooling2D((2, 2)))\n",
    "model.add(Activation('relu'))#Flatten\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(rate=0.2))#Add fully connected layer.\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(rate=0.2))#Output layer\n",
    "model.add(Dense(5))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "batch_size = 8\n",
    "learning_rate = 0.01\n",
    "decay_rate = learning_rate / epochs\n",
    "momentum = 0.9\n",
    "sgd = SGD(learning_rate=learning_rate, momentum=momentum, decay=decay_rate, nesterov=False)\n",
    "model.compile(optimizer=\"sgd\", loss=\"categorical_crossentropy\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\AppData\\Local\\Temp/ipykernel_31648/2132631962.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.5892 - accuracy: 0.2857WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 200 batches). You may need to use the repeat() function when building your dataset.\n",
      "4/4 [==============================] - 9s 2s/step - loss: 1.5892 - accuracy: 0.2857 - val_loss: 1.5121 - val_accuracy: 0.6095\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 5s 1s/step - loss: 1.5499 - accuracy: 0.1184\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 6s 1s/step - loss: 1.2689 - accuracy: 0.6579\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.3154 - accuracy: 1.0000\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 6s 1s/step - loss: 2.0149 - accuracy: 0.2895\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 5s 1s/step - loss: 1.1775 - accuracy: 0.4571\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 6s 1s/step - loss: 1.4384 - accuracy: 0.3421\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.8383 - accuracy: 0.5857\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 5s 1s/step - loss: 1.9743 - accuracy: 0.5000\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 5s 1s/step - loss: 1.0763 - accuracy: 1.0000\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 6s 1s/step - loss: 1.7619 - accuracy: 0.2500\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 6s 1s/step - loss: 1.2794 - accuracy: 0.5000\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.9624 - accuracy: 0.5789\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.7557 - accuracy: 0.6447\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - 5s 1s/step - loss: 1.6415 - accuracy: 0.4868\n",
      "Epoch 16/50\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.9474 - accuracy: 0.7500\n",
      "Epoch 17/50\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.4184 - accuracy: 1.0000\n",
      "Epoch 18/50\n",
      "4/4 [==============================] - 5s 1s/step - loss: 2.4604 - accuracy: 0.5000\n",
      "Epoch 19/50\n",
      "4/4 [==============================] - 5s 1s/step - loss: 1.4453 - accuracy: 0.3857\n",
      "Epoch 20/50\n",
      "4/4 [==============================] - 5s 1s/step - loss: 1.0752 - accuracy: 0.7500\n",
      "Epoch 21/50\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.9728 - accuracy: 0.7500\n",
      "Epoch 22/50\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.8318 - accuracy: 0.7500\n",
      "Epoch 23/50\n",
      "4/4 [==============================] - 6s 1s/step - loss: 1.6939 - accuracy: 0.2500\n",
      "Epoch 24/50\n",
      "4/4 [==============================] - 5s 1s/step - loss: 1.1221 - accuracy: 0.6571\n",
      "Epoch 25/50\n",
      "4/4 [==============================] - 6s 1s/step - loss: 1.2118 - accuracy: 0.7500\n",
      "Epoch 26/50\n",
      "4/4 [==============================] - 5s 1s/step - loss: 1.6635 - accuracy: 0.2500\n",
      "Epoch 27/50\n",
      "4/4 [==============================] - 6s 1s/step - loss: 1.4036 - accuracy: 0.5000\n",
      "Epoch 28/50\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.9604 - accuracy: 0.7500\n",
      "Epoch 29/50\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.8106 - accuracy: 0.7500\n",
      "Epoch 30/50\n",
      "4/4 [==============================] - 5s 1s/step - loss: 1.3017 - accuracy: 0.7500\n",
      "Epoch 31/50\n",
      "4/4 [==============================] - 6s 1s/step - loss: 1.3094 - accuracy: 0.5000\n",
      "Epoch 32/50\n",
      "4/4 [==============================] - 5s 1s/step - loss: 1.0495 - accuracy: 0.6842\n",
      "Epoch 33/50\n",
      "4/4 [==============================] - 6s 2s/step - loss: 1.0216 - accuracy: 0.6842\n",
      "Epoch 34/50\n",
      "4/4 [==============================] - 6s 2s/step - loss: 0.4266 - accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "4/4 [==============================] - 6s 1s/step - loss: 1.8592 - accuracy: 0.2500\n",
      "Epoch 36/50\n",
      "4/4 [==============================] - 6s 1s/step - loss: 1.1597 - accuracy: 0.7500\n",
      "Epoch 37/50\n",
      "4/4 [==============================] - 6s 2s/step - loss: 1.7492 - accuracy: 0.2500\n",
      "Epoch 38/50\n",
      "4/4 [==============================] - 6s 2s/step - loss: 1.6580 - accuracy: 0.2500\n",
      "Epoch 39/50\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.7826 - accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "4/4 [==============================] - 6s 2s/step - loss: 1.4513 - accuracy: 0.5000\n",
      "Epoch 41/50\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.9318 - accuracy: 0.7286\n",
      "Epoch 42/50\n",
      "4/4 [==============================] - 6s 1s/step - loss: 1.4641 - accuracy: 0.5000\n",
      "Epoch 43/50\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.9335 - accuracy: 0.6842\n",
      "Epoch 44/50\n",
      "4/4 [==============================] - 6s 2s/step - loss: 1.9507 - accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "4/4 [==============================] - 6s 2s/step - loss: 1.2817 - accuracy: 0.5000\n",
      "Epoch 46/50\n",
      "4/4 [==============================] - 6s 2s/step - loss: 1.3366 - accuracy: 0.5000\n",
      "Epoch 47/50\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.7471 - accuracy: 0.9286\n",
      "Epoch 48/50\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.9351 - accuracy: 0.7500\n",
      "Epoch 49/50\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.4271 - accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.7542 - accuracy: 0.7286\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21ed2ebaa90>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrainement du modèle\n",
    "model.fit_generator(\n",
    "        training_set,\n",
    "        steps_per_epoch=4,\n",
    "        epochs=50,\n",
    "        validation_data=test_set,\n",
    "        validation_steps=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\AppData\\Local\\Temp/ipykernel_31648/2186847382.py:2: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
      "  model.evaluate_generator(generator = test_set, steps=4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.6792891025543213, 0.46052631735801697]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluation du modèle\n",
    "model.evaluate_generator(generator = test_set, steps=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\AppData\\Local\\Temp/ipykernel_31648/2506516680.py:3: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  pred = model.predict_generator(test_set, steps=13, verbose=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 6/13 [============>.................] - ETA: 2sWARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 13 batches). You may need to use the repeat() function when building your dataset.\n",
      "13/13 [==============================] - 3s 175ms/step\n"
     ]
    }
   ],
   "source": [
    "#Prediction sur les données test\n",
    "test_set.reset()\n",
    "pred = model.predict_generator(test_set, steps=13, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'Artifact', 1: 'Extrahs', 2: 'Extrasystole', 3: 'Murmur', 4: 'Normal'}\n"
     ]
    }
   ],
   "source": [
    "# Labélisation des résultats\n",
    "predicted_class_indices = np.argmax(pred,axis=1)\n",
    "\n",
    "labels = (training_set.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "print(labels)\n",
    "predictions = [labels[k] for k in predicted_class_indices]\n",
    "predictions = predictions[:200]\n",
    "filenames = test_set.filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105 105\n"
     ]
    }
   ],
   "source": [
    "#On vérifie que le nombre de prediction = le nombre de files\n",
    "print(len(filenames),len(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Création d'un csv pour visualiser les résultats.\n",
    "results = pd.DataFrame({\"Filename\":filenames,\n",
    "\"Predictions\":predictions})\n",
    "results.to_csv('prediction_results.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "07efdcd4b820c98a756949507a4d29d7862823915ec7477944641bea022f4f62"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
